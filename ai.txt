Ниже — готовое **подробное описание работы ИИ** для раздела нововведений / ТЗ, с учетом ваших замечаний по слабым местам. Я также привязал это к текущей архитектуре проекта (у вас уже есть FastAPI modular monolith, Qdrant-поиск, click/search tracking и сервисный слой), чтобы новый функционал не конфликтовал с существующим поиском.    

---

# Подробное описание работы ИИ в новом функционале (поиск работы и сотрудников через Telegram-бот)

## 1. Общая идея нововведения

В существующий проект добавляется новый функциональный контур **Employment / Jobs**, который позволяет:

* **соискателям** искать работу;
* **работодателям (организациям/HR)** искать сотрудников;
* выполнять взаимодействие в формате **лайков/дизлайков и матчей** через Telegram-бот (по механике, похожей на “Дайвинчик”).

Ключевое отличие от обычного каталога — **умный AI-подбор**:

* система не только показывает анкеты, но и **ранжирует** их по релевантности;
* объясняет, **почему анкета подходит / не подходит**;
* подсказывает, **каких навыков не хватает**;
* строит аналитику для университетов и HR по востребованным навыкам и готовности студентов.

---

## 2. Как ИИ будет работать (главная логика)

### 2.1. Принцип подбора — не “магия”, а гибридная система

ИИ-подбор должен работать не только на генеративной модели и не только на эмбеддингах. Практически надежнее использовать **гибридную схему**:

1. **Структурированные данные (жесткие признаки)**

   * категория/направление;
   * навыки;
   * стек технологий;
   * опыт;
   * тип занятости;
   * город / удаленка;
   * желаемая роль.

2. **Семантическое сходство (эмбеддинги + Qdrant)**

   * сравнение текста резюме и описания вакансии;
   * поиск похожих профилей/вакансий по смыслу, даже если формулировки разные.

3. **Объясняющий слой (LLM / генеративная модель)**

   * формирование понятного объяснения:

     * какие навыки совпали;
     * чего не хватает;
     * что прокачать;
     * какие направления подходят.

> То есть ИИ здесь — это не один “процент”, а **конвейер из нормализации → поиска → ранжирования → объяснения**.

---

## 3. Почему нельзя отдавать “процент схожести” как есть (и как сделать правильно)

Ваше замечание абсолютно точное: если просто взять cosine similarity (или score модели) и назвать это “процентом”, пользователи будут воспринимать это как **точный показатель**, что вызовет споры и недоверие.

### Правильная модель оценки

Нужно разделить 3 сущности:

* **`match_score`** — внутренний числовой скор модели (например, 0.0–1.0), используется для ранжирования;
* **`match_percent_display`** — отображаемый процент (калиброванный/нормализованный для UI);
* **`match_explanation`** — объяснение результата.

### Пример

* Внутренний `match_score = 0.73`
* Пользователю показывается:

  * **“Подходит на 81%”**
  * “Совпадают навыки: Python, Django, PostgreSQL”
  * “Не хватает: Docker, CI/CD”
  * “Уровень опыта ниже желаемого на ~1 год”

### Что это дает

* понятный UX;
* меньше конфликтов с HR;
* честнее аналитика;
* возможность улучшать формулу без ломки UI.

---

## 4. Нормализация навыков — обязательный слой (иначе AI будет давать слабые объяснения)

Если оставить только свободный текст + эмбеддинги/генеративку, появятся проблемы:

* `PostgreSQL`, `Postgres`, `psql` будут считаться разными вещами;
* русский/казахский/английский дадут “языковую кашу”;
* аналитика по навыкам станет неточной;
* рекомендации “что изучить” будут нестабильными.

## 4.1. Минимальная таксономия навыков (обязательно)

Нужно добавить базовые сущности:

* **`skills_catalog`** — справочник навыков (канонические названия)
* **`skill_aliases`** — синонимы/алиасы (`Postgres`, `PostgreSQL`, `PG`)
* **`vacancy_skills`** — навыки вакансии (с весом, обязательностью)
* **`employ_skills`** — навыки соискателя (уровень, опыт, уверенность)
* (опционально) **`skills_groups`** — категории навыков (backend, data, soft skills и т.п.)

## 4.2. Что делает ИИ с навыками

1. Извлекает навыки из:

   * резюме;
   * описания профиля;
   * GitHub / портфолио (если подключено);
   * текста вакансии.
2. Приводит к каноническим skill_id через `skill_aliases`.
3. Сохраняет в структурированном виде.
4. Использует это в:

   * фильтрации;
   * скоринге;
   * объяснениях;
   * аналитике.

---

## 5. Архитектура AI-подбора (чтобы не сломать существующий поиск)

В проекте уже есть поисковый контур с Qdrant для контента (`clubs/campaigns/news`) и tracking поисковых/кликовых событий. Его нельзя просто “перемешать” с резюме и вакансиями — это ухудшит релевантность и аналитику. В текущем проекте поиск уже индексирует контентные сущности и использует собственный трекинг/персонализацию.  

## 5.1. Рекомендуемое решение

Сделать **отдельный employment-контур поиска**, а не смешивать с текущим search:

### Вариант A (предпочтительный)

* **Отдельная коллекция Qdrant** для employment (например: `employment_index`)
* Отдельные payload/фильтры/события
* Отдельный ранжировщик

### Вариант B

* Одна коллекция, но с `doc_type` (`vacancy`, `employ_profile`) + отдельные фильтры и логика ранжирования
  (сложнее, больше риск “перекрестного шума”)

### Почему лучше отдельная коллекция

* не загрязняется текущий поиск по клубам/новостям;
* проще управлять весами;
* проще внедрять объяснения и метрики;
* отдельная аналитика для HR/вузов.

---

## 6. Подробный AI-конвейер (pipeline) сопоставления вакансий и кандидатов

## 6.1. Этап 1 — Входные данные и регистрация через Telegram-бот

### Для любого пользователя (соискатель / организация)

1. Бот получает `telegram_id`.
2. Вызывает эндпоинт проверки `telegram_id`:

   * зарегистрирован ли пользователь в боте;
   * есть ли запись в `tg_info`;
   * не заблокирован ли аккаунт.
3. Если пользователь новый — создается/обновляется запись в `tg_info`.

### Для организации

Перед созданием профиля:

1. бот дергает эндпоинт **валидации email** (проверка дубля);
2. если email свободен — дергает эндпоинт создания пользователя/организации;
3. API возвращает введенные данные обратно для предпросмотра анкеты.

### Для соискателя

* регистрируется профиль `Employ` (без полиморфизма — как отдельная сущность, как вы и указали);
* заполняется описание (JSON), ссылки, email.

---

## 6.2. Этап 2 — Парсинг и нормализация профиля/вакансии

После сохранения анкеты запускается AI-обработка (синхронно или фоново в зависимости от UX):

### Для `Employ`

Система анализирует:

* `description` (JSON от фронта/бота);
* `links[]` (GitHub, portfolio, LinkedIn и т.п.);
* (если будет) текст резюме;
* карьерную категорию пользователя.

### Для `Vacancy`

Система анализирует:

* название вакансии (`role_search`);
* описание вакансии (`description` JSON);
* требования к навыкам/технологиям;
* soft skills;
* опыт.

### Результат нормализации

Формируются:

* нормализованный текст для эмбеддинга;
* список skills (канонический);
* признаки для фильтрации и скоринга.

---

## 6.3. Этап 3 — Векторизация (Embeddings) и индексирование в Qdrant

Для каждой анкеты и вакансии создается embedding-вектор.

### Что индексируется

* **Профили соискателей** → документы типа `employ_profile`
* **Вакансии** → документы типа `vacancy`

### Что кладется в payload Qdrant

Примерно:

* `doc_type`
* `entity_id`
* `organization_id` / `employ_id`
* `category`
* `skills[]`
* `city`
* `employment_type`
* `experience_level`
* `is_active`
* `language`
* timestamps / version

### Важно

Индексируется не “сырой текст”, а **очищенный и нормализованный профиль**, чтобы:

* повысить качество поиска;
* не тащить мусор в эмбеддинги;
* сохранить объяснимость.

---

## 6.4. Этап 4 — Кандидатный поиск (candidate generation)

Когда работодатель открывает вакансию и хочет “подобрать работников”, или соискатель ищет вакансии, система сначала делает **быстрый предварительный отбор**:

### Примеры фильтров до AI-скоринга

* активность анкеты/вакансии;
* категория;
* регион / remote;
* желаемая роль;
* минимальный уровень;
* обязательные навыки (если отмечены как hard requirement).

После этого берется ограниченный пул (например, top 200) и передается в AI-ранжирование.

---

## 6.5. Этап 5 — AI-скоринг (ранжирование)

Итоговый `match_score` считается как комбинация нескольких факторов (весовая модель).

### Пример структуры скоринга

* **Semantic score (эмбеддинги)** — 35–50%
* **Совпадение навыков (hard skills)** — 25–35%
* **Совпадение технологии/стека** — 10–20%
* **Опыт / seniority** — 5–15%
* **Soft skills / предпочтения** — 5–10%
* **Поведенческие сигналы** (лайки/матчи/отклики) — 0–15% (после накопления данных)

> На старте поведенческий вес должен быть минимальным, чтобы не ухудшить cold-start.

### Почему это лучше, чем просто cosine similarity

* можно объяснять результат по компонентам;
* можно калибровать под разные роли;
* можно отдельно оптимизировать точность для студентов/HR.

---

## 6.6. Этап 6 — Калибровка “процента соответствия” для UI

`match_score` → преобразуется в `match_percent_display`

### Что делает калибровка

* сглаживает слишком “жесткие” значения;
* делает проценты понятнее для пользователей;
* учитывает качество данных (полнота профиля, наличие резюме, структура вакансии).

### Дополнительно (желательно)

Показывать не только процент, но и **уровень уверенности**:

* Высокая уверенность
* Средняя
* Низкая (например, если данных мало)

Это закрывает проблему “обманчивого процента”.

---

## 6.7. Этап 7 — Генерация объяснения и рекомендаций

После ранжирования система формирует **explanation**.

### Для работодателя

* почему кандидат подходит;
* какие навыки совпали;
* какие требования не закрыты;
* что является риском (например, недостаточный опыт).

### Для соискателя

* какие вакансии подходят больше всего;
* чего не хватает для лучших вакансий;
* какие навыки прокачать;
* рекомендованные карьерные направления;
* (опционально) какие курсы/проекты помогут.

### Формат explanation (лучше хранить как JSON)

Чтобы UI мог красиво отрисовать:

* `matched_skills[]`
* `missing_skills[]`
* `strengths[]`
* `risks[]`
* `recommended_next_steps[]`
* `confidence_level`

---

## 7. Cold-start стратегия (обязательно, иначе первые пользователи получат плохой опыт)

Вы правильно указали проблему: если профиль пустой или вакансия короткая, AI работает слабо.

## 7.1. Что делать при пустом/слабом профиле соискателя

Если мало данных:

* использовать категорию + роль + базовые навыки из короткой анкеты;
* предложить “быстрое заполнение” (чеклист навыков);
* показывать популярные вакансии по категории;
* включать onboarding-рекомендации (что добавить в профиль для лучших матчей).

## 7.2. Что делать при слабой вакансии

Если у вакансии мало описания:

* просить работодателя заполнить обязательные поля;
* автоматически извлекать требования из названия (черновой режим);
* снижать уверенность в процентах;
* показывать предупреждение “описание вакансии слишком короткое, точность подбора ниже”.

## 7.3. Что делать без истории лайков/кликов

Пока нет поведения:

* ранжировать по content-based признакам (skills + embedding + category);
* использовать базовую популярность / свежесть вакансии;
* не включать персонализацию в полный вес.

---

## 8. Логика лайков, дизлайков и матчей (связка с AI)

## 8.1. Базовый поток

1. Пользователю (инициатору) показывается анкета, подобранная AI.
2. Он отправляет лайк/дизлайк.
3. Система сохраняет действие.
4. Если это лайк:

   * второй стороне приходит уведомление (в т.ч. email, как вы указали);
   * создается запись ожидания ответного действия.
5. Когда вторая сторона отвечает:

   * если лайк в ответ → **матч**
   * если дизлайк → матч не создается
6. После обработки временная запись может удаляться, но **история действий должна остаться**.

## 8.2. Важное улучшение к вашей модели (рекомендация)

Не хранить только одну “таблицу матчей (схожестей)” и удалять ее полностью после матча, иначе вы потеряете данные для аналитики и обучения.

Лучше разделить:

* **`match_intents` / `match_actions`** — история лайков/дизлайков (не удаляется)
* **`matches`** — факт взаимного лайка (может быть активный/закрытый)
* **`notifications_log`** — что/кому отправили (email/telegram)

Тогда:

* бизнес-логика “как в боте” сохранится;
* данные для AI-улучшения не потеряются.

---

## 9. История изменений резюме и развитие пользователя (очень важная часть для аналитики)

Вы указали, что система должна хранить историю изменений резюме — это сильное решение.

## 9.1. Что хранить

Не только “последнюю версию”, а версии:

* текст/JSON профиля;
* навыки на момент версии;
* ссылки;
* AI-оценки (snapshot);
* дата изменения.

## 9.2. Что это даст

* динамика развития студента;
* “до/после” после обучения/курсов;
* аналитика готовности к рынку;
* качество рекомендаций (какие подсказки реально улучшают match).

---

## 10. Аналитика для университетов и HR (на базе AI, но с прозрачными метриками)

## 10.1. Что можно показывать

### Университетам

* востребованные навыки по направлениям;
* разрыв между навыками студентов и требованиями вакансий;
* динамика готовности студентов по потокам/курсам;
* популярные карьерные треки.

### HR / работодателям

* дефицитные навыки по рынку;
* средний уровень соответствия кандидатов по вакансиям;
* где чаще “ломается” воронка (просмотр → лайк → матч → контакт);
* какие требования слишком завышены.

## 10.2. Важное замечание

Метрика “готовность студентов” не должна считаться только по одному “проценту”.
Нужны составные показатели:

* coverage hard skills,
* experience fit,
* semantic fit,
* profile completeness,
* confidence.

---

## 11. Предлагаемое описание AI-сервиса для ТЗ (готовый текст, можно вставлять)

Ниже — версия, уже в более формальном виде.

### AI-сервис сопоставления кандидатов и вакансий (расширенное описание)

Разрабатывается отдельный AI-сервис (в рамках нового функционального контура Employment), предназначенный для интеллектуального сопоставления профилей соискателей и вакансий работодателей.

#### Основные задачи AI-сервиса

1. Автоматически анализировать анкеты соискателей и вакансии.
2. Вычислять релевантность кандидата к вакансии (и вакансии к кандидату).
3. Формировать объяснение результатов сопоставления:

   * совпадающие навыки,
   * недостающие навыки,
   * сильные стороны,
   * рекомендации по развитию.
4. Поддерживать аналитику для университетов и HR по востребованным навыкам и уровню готовности студентов к рынку труда.

#### Принцип работы

AI-сервис использует гибридный подход:

* структурированный анализ навыков, опыта, технологий и карьерных предпочтений;
* семантическое сопоставление текстов профиля и вакансии через embeddings + векторный поиск (Qdrant);
* генерацию объяснений и рекомендаций через LLM/генеративную модель.

#### Важные особенности реализации

* Процент соответствия, отображаемый пользователю, не является “сырым” score модели.
  Система разделяет:

  * внутренний `match_score`,
  * отображаемый `match_percent_display`,
  * объяснение `match_explanation`.
* Для повышения качества объяснений и аналитики используется нормализация навыков (единый каталог навыков и таблица алиасов).
* Для исключения влияния на существующий контентный поиск проекта employment-поиск хранится в отдельной векторной коллекции / отдельном поисковом контуре.

#### Результат для соискателя

* список подходящих вакансий с ранжированием;
* процент соответствия (калиброванный);
* объяснение “почему подходит/не подходит”;
* рекомендации по развитию навыков и карьерного направления.

#### Результат для работодателя

* список наиболее релевантных кандидатов под конкретную вакансию;
* процент соответствия и детализация недостающих компетенций;
* приоритетный список кандидатов для дальнейшего контакта.

---

## 12. Что стоит добавить в ТЗ по данным (чтобы AI реально работал качественно)

Помимо ваших таблиц `employ`, `vacancy`, `matches`, желательно добавить (или предусмотреть как следующий этап):

### Обязательный минимум для AI

* `skills_catalog`
* `skill_aliases`
* `employ_skills`
* `vacancy_skills`
* `resume_versions` / `employ_profile_history`
* `ai_match_scores` (snapshot результатов)
* `ai_match_explanations` (json)
* `tg_info` (если еще нет)
* `like_dislike_actions` (история реакций)

### Почему это важно

Без этого:

* объяснения будут слабее;
* аналитика — шумнее;
* обучение и улучшение подборов — сложнее.

---

## 13. Рекомендации по API-эндпоинтам для AI-части (логически)

Вы уже описали нужные эндпоинты, ниже — как их лучше концептуально разделить:

### Регистрация / проверка

* проверка `telegram_id` в `tg_info`
* валидация email организации
* создание профиля организации
* создание профиля соискателя
* получение своей анкеты (preview)

### Вакансии работодателя

* список моих вакансий (краткий)
* детали вакансии
* создать/обновить вакансию
* активировать/деактивировать вакансию

### AI-подбор

* получить список подходящих кандидатов для вакансии
* получить список подходящих вакансий для соискателя
* получить объяснение совпадения по конкретной паре (vacancy ↔ employ)

### Лайки / дизлайки / матчи

* отправить реакцию (like/dislike)
* получить статус реакции/матча
* получить список матчей
* лог уведомлений (внутренний/служебный)

### История и аналитика

* история изменений профиля (соискатель)
* аналитика навыков (HR/университет)
* динамика соответствия рынку

---

## 14. Отдельно — формулировка про “все Google” (как лучше написать)

Вы упомянули “либо генеративная модель или embedding и qdrant, все google”. Это лучше оформить так:

> AI-контур подбора реализуется на базе Google AI-моделей:
>
> * embedding-модель для семантического представления профилей и вакансий;
> * генеративная модель для построения объяснений, рекомендаций и карьерных подсказок;
> * векторное хранилище Qdrant для быстрого поиска похожих кандидатов и вакансий.

Так формулировка выглядит профессионально и технически корректно.

---

Если хотите, следующим сообщением могу сделать **уже финальную версию для вставки в “текстовый файл описания проекта”** в формате:

* **Раздел “Нововведение”**
* **Раздел “Работа ИИ”**
* **Раздел “Преимущества”**
* **Раздел “Риски и ограничения”**
* **Раздел “Этапы внедрения (MVP → v2)”**

(без воды, в стиле ТЗ/дипломного проекта).

